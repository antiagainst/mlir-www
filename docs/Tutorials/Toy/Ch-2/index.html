<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Chapter 2: Emitting Basic MLIR - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.59.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/llvm-project/mlir>Forums</a></li><li class=child><a href=https://discord.gg/JUQUPAZ>Chat</a></li></ul></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source</a></li></ul></nav></div><div class=content-container><main><h1>Chapter 2: Emitting Basic MLIR</h1><p>[TOC]</p><p>Now that we&rsquo;re familiar with our language and the AST, let&rsquo;s see how MLIR can
help to compile Toy.</p><h2 id=introduction-multi-level-intermediate-representation>Introduction: Multi-Level Intermediate Representation</h2><p>Other compilers, like LLVM (see the
<a href=https://llvm.org/docs/tutorial/MyFirstLanguageFrontend/index.html>Kaleidoscope tutorial</a>),
offer a fixed set of predefined types and (usually <em>low-level</em> / RISC-like)
instructions. It is up to the frontend for a given language to perform any
language-specific type-checking, analysis, or transformation before emitting
LLVM IR. For example, Clang will use its AST to perform not only static analysis
but also transformations, such as C++ template instantiation through AST cloning
and rewrite. Finally, languages with construction at a higher-level than C/C++
may require non-trivial lowering from their AST to generate LLVM IR.</p><p>As a consequence, multiple frontends end up reimplementing significant pieces of
infrastructure to support the need for these analyses and transformation. MLIR
addresses this issue by being designed for extensibility. As such, there are few
pre-defined instructions (<em>operations</em> in MLIR terminology) or types.</p><h2 id=interfacing-with-mlir>Interfacing with MLIR</h2><p><a href=../../LangRef.md>Language reference</a></p><p>MLIR is designed to be a completely extensible infrastructure; there is no
closed set of attributes (think: constant metadata), operations, or types. MLIR
supports this extensibility with the concept of
<a href=../../LangRef.md#dialects>Dialects</a>. Dialects provide a grouping mechanism for
abstraction under a unique <code>namespace</code>.</p><p>In MLIR, <a href=../../LangRef.md#operations><code>Operations</code></a> are the core unit of
abstraction and computation, similar in many ways to LLVM instructions.
Operations can have application-specific semantics and can be used to represent
all of the core IR structures in LLVM: instructions, globals (like functions),
modules, etc.</p><p>Here is the MLIR assembly for the Toy <code>transpose</code> operations:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>%t_tensor = &#34;toy.transpose&#34;(%tensor) {inplace = true} : (tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt; loc(&#34;example/file/path&#34;:12:1)</code></pre></div><p>Let&rsquo;s break down the anatomy of this MLIR operation:</p><ul><li><p><code>%t_tensor</code></p><ul><li>The name given to the result defined by this operation (which includes
<a href=../../LangRef.md#identifiers-and-keywords>a prefixed sigil to avoid collisions</a>).
An operation may define zero or more results (in the context of Toy, we
will limit ourselves to single-result operations), which are SSA values.
The name is used during parsing but is not persistent (e.g., it is not
tracked in the in-memory representation of the SSA value).</li></ul></li><li><p><code>&quot;toy.transpose&quot;</code></p><ul><li>The name of the operation. It is expected to be a unique string, with
the namespace of the dialect prefixed before the &ldquo;<code>.</code>&rdquo;. This can be read
as the <code>transpose</code> operation in the <code>toy</code> dialect.</li></ul></li><li><p><code>(%tensor)</code></p><ul><li>A list of zero or more input operands (or arguments), which are SSA
values defined by other operations or referring to block arguments.</li></ul></li><li><p><code>{ inplace = true }</code></p><ul><li>A dictionary of zero or more attributes, which are special operands that
are always constant. Here we define a boolean attribute named &lsquo;inplace&rsquo;
that has a constant value of true.</li></ul></li><li><p><code>(tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt;</code></p><ul><li>This refers to the type of the operation in a functional form, spelling
the types of the arguments in parentheses and the type of the return
values afterward.</li></ul></li><li><p><code>loc(&quot;example/file/path&quot;:12:1)</code></p><ul><li>This is the location in the source code from which this operation
originated.</li></ul></li></ul><p>Shown here is the general form of an operation. As described above, the set of
operations in MLIR is extensible. This means that the infrastructure must be
able to opaquely reason about the structure of an operation. This is done by
boiling down the composition of an operation into discrete pieces:</p><ul><li>A name for the operation.</li><li>A list of SSA operand values.</li><li>A list of <a href=../../LangRef.md#attributes>attributes</a>.</li><li>A list of <a href=../../LangRef.md#type-system>types</a> for result values.</li><li>A <a href=../../Diagnostics.md#source-locations>source location</a> for debugging
purposes.</li><li>A list of successors <a href=../../LangRef.md#blocks>blocks</a> (for branches,
mostly).</li><li>A list of <a href=../../LangRef.md#regions>regions</a> (for structural operations
like functions).</li></ul><p>In MLIR, every operation has a mandatory source location associated with it.
Contrary to LLVM, where debug info locations are metadata and can be dropped, in
MLIR, the location is a core requirement, and APIs depend on and manipulate it.
Dropping a location is thus an explicit choice which cannot happen by mistake.</p><p>To provide an illustration: If a transformation replaces an operation by
another, that new operation must still have a location attached. This makes it
possible to track where that operation came from.</p><p>It&rsquo;s worth noting that the mlir-opt tool - a tool for testing
compiler passes - does not include locations in the output by default. The
<code>-mlir-print-debuginfo</code> flag specifies to include locations. (Run <code>mlir-opt
--help</code> for more options.)</p><h3 id=opaque-api>Opaque API</h3><p>MLIR is designed to be a completely extensible system, and as such, the
infrastructure has the capability to opaquely represent all of its core
components: attributes, operations, types, etc. This allows MLIR to parse,
represent, and <a href=../../Glossary.md#round-trip>round-trip</a> any valid IR. For
example, we could place our Toy operation from above into an <code>.mlir</code> file and
round-trip through <em>mlir-opt</em> without registering anything:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>func @toy_func(%tensor: tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt; {
  %t_tensor = &#34;toy.transpose&#34;(%tensor) { inplace = true } : (tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;3x2xf64&gt;
  return %t_tensor : tensor&lt;3x2xf64&gt;
}</code></pre></div><p>In the cases of unregistered attributes, operations, and types, MLIR will
enforce some structural constraints (SSA, block termination, etc.), but
otherwise they are completely opaque. This can be useful for bootstrapping
purposes, but it is generally advised against. Opaque operations must be treated
conservatively by transformations and analyses, and they are much harder to
construct and manipulate.</p><p>This handling can be observed by crafting what should be an invalid IR for Toy
and seeing it round-trip without tripping the verifier:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>// RUN: toyc %s -emit=mlir

func @main() {
  %0 = &#34;toy.print&#34;() : () -&gt; tensor&lt;2x3xf64&gt;
}</code></pre></div><p>There are multiple problems here: the <code>toy.print</code> operation is not a terminator;
it should take an operand; and it shouldn&rsquo;t return any values. In the next
section, we will register our dialect and operations with MLIR, plug into the
verifier, and add nicer APIs to manipulate our operations.</p><h2 id=defining-a-toy-dialect>Defining a Toy Dialect</h2><p>To effectively interface with MLIR, we will define a new Toy dialect. This
dialect will properly model the semantics of the Toy language, as well as
provide an easy avenue for high-level analysis and transformation.</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=c1>/// This is the definition of the Toy dialect. A dialect inherits from
</span><span class=c1>/// mlir::Dialect and registers custom attributes, operations, and types (in its
</span><span class=c1>/// constructor). It can also override some general behavior exposed via virtual
</span><span class=c1>/// methods, which will be demonstrated in later chapters of the tutorial.
</span><span class=c1></span><span class=k>class</span> <span class=nc>ToyDialect</span> <span class=o>:</span> <span class=k>public</span> <span class=n>mlir</span><span class=o>::</span><span class=n>Dialect</span> <span class=p>{</span>
 <span class=k>public</span><span class=o>:</span>
  <span class=k>explicit</span> <span class=n>ToyDialect</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>MLIRContext</span> <span class=o>*</span><span class=n>ctx</span><span class=p>);</span>

  <span class=c1>/// Provide a utility accessor to the dialect namespace. This is used by
</span><span class=c1></span>  <span class=c1>/// several utilities.
</span><span class=c1></span>  <span class=k>static</span> <span class=n>llvm</span><span class=o>::</span><span class=n>StringRef</span> <span class=n>getDialectNamespace</span><span class=p>()</span> <span class=p>{</span> <span class=k>return</span> <span class=s>&#34;toy&#34;</span><span class=p>;</span> <span class=p>}</span>
<span class=p>};</span>
</code></pre></div><p>The dialect can now be registered in the global registry:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++>  <span class=n>mlir</span><span class=o>::</span><span class=n>registerDialect</span><span class=o>&lt;</span><span class=n>ToyDialect</span><span class=o>&gt;</span><span class=p>();</span>
</code></pre></div><p>Any new <code>MLIRContext</code> created from now on will contain an instance of the Toy
dialect and invoke specific hooks for things like parsing attributes and types.</p><h2 id=defining-toy-operations>Defining Toy Operations</h2><p>Now that we have a <code>Toy</code> dialect, we can start registering operations. This will
allow for providing semantic information that the rest of the system can hook
into. Let&rsquo;s walk through the creation of the <code>toy.constant</code> operation:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir> %4 = &#34;toy.constant&#34;() {value = dense&lt;1.0&gt; : tensor&lt;2x3xf64&gt;} : () -&gt; tensor&lt;2x3xf64&gt;</code></pre></div><p>This operation takes zero operands, a
<a href=../../LangRef.md#dense-elements-attribute>dense elements</a> attribute named
<code>value</code>, and returns a single result of
<a href=../../LangRef.md#tensor-type>TensorType</a>. An operation inherits from the
<a href=https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern>CRTP</a>
<code>mlir::Op</code> class which also takes some optional <a href=../../Traits.md><em>traits</em></a> to
customize its behavior. These traits may provide additional accessors,
verification, etc.</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=k>class</span> <span class=nc>ConstantOp</span> <span class=o>:</span> <span class=k>public</span> <span class=n>mlir</span><span class=o>::</span><span class=n>Op</span><span class=o>&lt;</span><span class=n>ConstantOp</span><span class=p>,</span>
                     <span class=c1>/// The ConstantOp takes zero inputs.
</span><span class=c1></span>                     <span class=n>mlir</span><span class=o>::</span><span class=n>OpTrait</span><span class=o>::</span><span class=n>ZeroOperands</span><span class=p>,</span>
                     <span class=c1>/// The ConstantOp returns a single result.
</span><span class=c1></span>                     <span class=n>mlir</span><span class=o>::</span><span class=n>OpTrait</span><span class=o>::</span><span class=n>OneResult</span><span class=p>,</span>
                     <span class=c1>/// The ConstantOp is pure and has no visible side-effects.
</span><span class=c1></span>                     <span class=n>mlir</span><span class=o>::</span><span class=n>OpTrait</span><span class=o>::</span><span class=n>HasNoSideEffect</span><span class=o>&gt;</span> <span class=p>{</span>

 <span class=k>public</span><span class=o>:</span>
  <span class=c1>/// Inherit the constructors from the base Op class.
</span><span class=c1></span>  <span class=k>using</span> <span class=n>Op</span><span class=o>::</span><span class=n>Op</span><span class=p>;</span>

  <span class=c1>/// Provide the unique name for this operation. MLIR will use this to register
</span><span class=c1></span>  <span class=c1>/// the operation and uniquely identify it throughout the system.
</span><span class=c1></span>  <span class=k>static</span> <span class=n>llvm</span><span class=o>::</span><span class=n>StringRef</span> <span class=n>getOperationName</span><span class=p>()</span> <span class=p>{</span> <span class=k>return</span> <span class=s>&#34;toy.constant&#34;</span><span class=p>;</span> <span class=p>}</span>

  <span class=c1>/// Return the value of the constant by fetching it from the attribute.
</span><span class=c1></span>  <span class=n>mlir</span><span class=o>::</span><span class=n>DenseElementsAttr</span> <span class=n>getValue</span><span class=p>();</span>

  <span class=c1>/// Operations can provide additional verification beyond the traits they
</span><span class=c1></span>  <span class=c1>/// define. Here we will ensure that the specific invariants of the constant
</span><span class=c1></span>  <span class=c1>/// operation are upheld, for example the result type must be of TensorType.
</span><span class=c1></span>  <span class=n>LogicalResult</span> <span class=nf>verify</span><span class=p>();</span>

  <span class=c1>/// Provide an interface to build this operation from a set of input values.
</span><span class=c1></span>  <span class=c1>/// This interface is used by the builder to allow for easily generating
</span><span class=c1></span>  <span class=c1>/// instances of this operation:
</span><span class=c1></span>  <span class=c1>///   mlir::OpBuilder::create&lt;ConstantOp&gt;(...)
</span><span class=c1></span>  <span class=c1>/// This method populates the given `state` that MLIR uses to create
</span><span class=c1></span>  <span class=c1>/// operations. This state is a collection of all of the discrete elements
</span><span class=c1></span>  <span class=c1>/// that an operation may contain.
</span><span class=c1></span>  <span class=c1>/// Build a constant with the given return type and `value` attribute.
</span><span class=c1></span>  <span class=k>static</span> <span class=kt>void</span> <span class=nf>build</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>Builder</span> <span class=o>*</span><span class=n>builder</span><span class=p>,</span> <span class=n>mlir</span><span class=o>::</span><span class=n>OperationState</span> <span class=o>&amp;</span><span class=n>state</span><span class=p>,</span>
                    <span class=n>mlir</span><span class=o>::</span><span class=n>Type</span> <span class=n>result</span><span class=p>,</span> <span class=n>mlir</span><span class=o>::</span><span class=n>DenseElementsAttr</span> <span class=n>value</span><span class=p>);</span>
  <span class=c1>/// Build a constant and reuse the type from the given &#39;value&#39;.
</span><span class=c1></span>  <span class=k>static</span> <span class=kt>void</span> <span class=nf>build</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>Builder</span> <span class=o>*</span><span class=n>builder</span><span class=p>,</span> <span class=n>mlir</span><span class=o>::</span><span class=n>OperationState</span> <span class=o>&amp;</span><span class=n>state</span><span class=p>,</span>
                    <span class=n>mlir</span><span class=o>::</span><span class=n>DenseElementsAttr</span> <span class=n>value</span><span class=p>);</span>
  <span class=c1>/// Build a constant by broadcasting the given &#39;value&#39;.
</span><span class=c1></span>  <span class=k>static</span> <span class=kt>void</span> <span class=nf>build</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>Builder</span> <span class=o>*</span><span class=n>builder</span><span class=p>,</span> <span class=n>mlir</span><span class=o>::</span><span class=n>OperationState</span> <span class=o>&amp;</span><span class=n>state</span><span class=p>,</span>
                    <span class=kt>double</span> <span class=n>value</span><span class=p>);</span>
<span class=p>};</span>
</code></pre></div><p>and we register this operation in the <code>ToyDialect</code> constructor:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=n>ToyDialect</span><span class=o>::</span><span class=n>ToyDialect</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>MLIRContext</span> <span class=o>*</span><span class=n>ctx</span><span class=p>)</span>
    <span class=o>:</span> <span class=n>mlir</span><span class=o>::</span><span class=n>Dialect</span><span class=p>(</span><span class=n>getDialectNamespace</span><span class=p>(),</span> <span class=n>ctx</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>addOperations</span><span class=o>&lt;</span><span class=n>ConstantOp</span><span class=o>&gt;</span><span class=p>();</span>
<span class=p>}</span>
</code></pre></div><h3 id=op-vs-operation-using-mlir-operations>Op vs Operation: Using MLIR Operations</h3><p>Now that we have defined an operation, we will want to access and transform it.
In MLIR, there are two main classes related to operations: <code>Operation</code> and <code>Op</code>.
Operation is the actual opaque instance of the operation, and represents the
general API into an operation instance. An <code>Op</code> is the base class of a derived
operation, like <code>ConstantOp</code>, and acts as smart pointer wrapper around a
<code>Operation*</code>. This means that when we define our Toy operations, we are actually
providing a clean interface for building and interfacing with the <code>Operation</code>
class; this is why our <code>ConstantOp</code> defines no class fields. Therefore, we
always pass these classes around by value, instead of by reference or pointer
(<em>passing by value</em> is a common idiom and applies similarly to attributes,
types, etc). We can always get an instance of our toy operation by using LLVM&rsquo;s
casting infrastructure:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=kt>void</span> <span class=nf>processConstantOp</span><span class=p>(</span><span class=n>mlir</span><span class=o>::</span><span class=n>Operation</span> <span class=o>*</span><span class=n>operation</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>ConstantOp</span> <span class=n>op</span> <span class=o>=</span> <span class=n>llvm</span><span class=o>::</span><span class=n>dyn_cast</span><span class=o>&lt;</span><span class=n>ConstantOp</span><span class=o>&gt;</span><span class=p>(</span><span class=n>operation</span><span class=p>);</span>

  <span class=c1>// This operation is not an instance of `ConstantOp`.
</span><span class=c1></span>  <span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>op</span><span class=p>)</span>
    <span class=k>return</span><span class=p>;</span>

  <span class=c1>// Get the internal operation instance back.
</span><span class=c1></span>  <span class=n>mlir</span><span class=o>::</span><span class=n>Operation</span> <span class=o>*</span><span class=n>internalOperation</span> <span class=o>=</span> <span class=n>op</span><span class=p>.</span><span class=n>getOperation</span><span class=p>();</span>
  <span class=n>assert</span><span class=p>(</span><span class=n>internalOperation</span> <span class=o>==</span> <span class=n>operation</span> <span class=o>&amp;&amp;</span>
         <span class=s>&#34;these operation instances are the same&#34;</span><span class=p>);</span>
<span class=p>}</span>
</code></pre></div><h3 id=using-the-operation-definition-specification-ods-framework>Using the Operation Definition Specification (ODS) Framework</h3><p>In addition to specializing the <code>mlir::Op</code> C++ template, MLIR also supports
defining operations in a declarative manner. This is achieved via the
<a href=../../OpDefinitions.md>Operation Definition Specification</a> framework. Facts
regarding an operation are specified concisely into a TableGen record, which
will be expanded into an equivalent <code>mlir::Op</code> C++ template specialization at
compile time. Using the ODS framework is the desired way for defining operations
in MLIR given the simplicity, conciseness, and general stability in the face of
C++ API changes.</p><p>Lets see how to define the ODS equivalent of our ConstantOp:</p><p>The first thing to do is to define a link to the Toy dialect that we defined in
C++. This is used to link all of the operations that we will define to our
dialect:</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>// Provide a definition of the &#39;toy&#39; dialect in the ODS framework so that we
// can define our operations.
def Toy_Dialect : Dialect {
  // The namespace of our dialect, this corresponds 1-1 with the string we
  // provided in `ToyDialect::getDialectNamespace`.
  let name = &#34;toy&#34;;

  // The C++ namespace that the dialect class definition resides in.
  let cppNamespace = &#34;toy&#34;;
}</code></pre></div><p>Now that we have defined a link to the Toy dialect, we can start defining
operations. Operations in ODS are defined by inheriting from the <code>Op</code> class. To
simplify our operation definitions, we will define a base class for operations
in the Toy dialect.</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>// Base class for toy dialect operations. This operation inherits from the base
// `Op` class in OpBase.td, and provides:
//   * The parent dialect of the operation.
//   * The mnemonic for the operation, or the name without the dialect prefix.
//   * A list of traits for the operation.
class Toy_Op&lt;string mnemonic, list&lt;OpTrait&gt; traits = []&gt; :
    Op&lt;Toy_Dialect, mnemonic, traits&gt;;</code></pre></div><p>With all of the preliminary pieces defined, we can begin to define the constant
operation.</p><p>We define a toy operation by inheriting from our base &lsquo;Toy_Op&rsquo; class above. Here
we provide the mnemonic and a list of traits for the operation. The
<a href=../../OpDefinitions.md#operation-name>mnemonic</a> here matches the one given in
<code>ConstantOp::getOperationName</code> without the dialect prefix; <code>toy.</code>. The constant
operation here is also marked as &lsquo;NoSideEffect&rsquo;. This is an ODS trait, and
matches one-to-one with the trait we providing when defining <code>ConstantOp</code>:
<code>mlir::OpTrait::HasNoSideEffect</code>. Missing here from our C++ definition are the
<code>ZeroOperands</code> and <code>OneResult</code> traits; these will be automatically inferred
based upon the <code>arguments</code> and <code>results</code> fields we define later.</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>def ConstantOp : Toy_Op&lt;&#34;constant&#34;, [NoSideEffect]&gt; {
}</code></pre></div><p>At this point you probably might want to know what the C++ code generated by
TableGen looks like. Simply run the <code>mlir-tblgen</code> command with the
<code>gen-op-decls</code> or the <code>gen-op-defs</code> action like so:</p><pre><code>${build_root}/bin/mlir-tblgen -gen-op-defs ${mlir_src_root}/examples/toy/Ch2/include/toy/Ops.td -I ${mlir_src_root}/include/
</code></pre><p>Depending on the selected action, this will print either the <code>ConstantOp</code> class
declaration or its implementation. Comparing this output to the hand-crafted
implementation is incredibly useful when getting started with TableGen.</p><h4 id=defining-arguments-and-results>Defining Arguments and Results</h4><p>With the shell of the operation defined, we can now provide the
<a href=../../OpDefinitions.md#operation-arguments>inputs</a> and
<a href=../../OpDefinitions.md#operation-results>outputs</a> to our operation. The
inputs, or arguments, to an operation may be attributes or types for SSA operand
values. The results correspond to a set of types for the values produced by the
operation:</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>def ConstantOp : Toy_Op&lt;&#34;constant&#34;, [NoSideEffect]&gt; {
  // The constant operation takes an attribute as the only input.
  // `F64ElementsAttr` corresponds to a 64-bit floating-point ElementsAttr.
  let arguments = (ins F64ElementsAttr:$value);

  // The constant operation returns a single value of TensorType.
  // F64Tensor corresponds to a 64-bit floating-point TensorType.
  let results = (outs F64Tensor);
}</code></pre></div><p>By providing a name to the arguments or results, e.g. <code>$value</code>, ODS will
automatically generate a matching accessor: <code>DenseElementsAttr
ConstantOp::value()</code>.</p><h4 id=adding-documentation>Adding Documentation</h4><p>The next step after defining the operation is to document it. Operations may
provide
<a href=../../OpDefinitions.md#operation-documentation><code>summary</code> and <code>description</code></a>
fields to describe the semantics of the operation. This information is useful
for users of the dialect and can even be used to auto-generate Markdown
documents.</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>def ConstantOp : Toy_Op&lt;&#34;constant&#34;, [NoSideEffect]&gt; {
  // Provide a summary and description for this operation. This can be used to
  // auto-generate documentation of the operations within our dialect.
  let summary = &#34;constant operation&#34;;
  let description = [{
    Constant operation turns a literal into an SSA value. The data is attached
    to the operation as an attribute. For example:

      %0 = &#34;toy.constant&#34;()
         { value = dense&lt;[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]&gt; : tensor&lt;2x3xf64&gt; }
        : () -&gt; tensor&lt;2x3xf64&gt;
  }];

  // The constant operation takes an attribute as the only input.
  // `F64ElementsAttr` corresponds to a 64-bit floating-point ElementsAttr.
  let arguments = (ins F64ElementsAttr:$value);

  // The generic call operation returns a single value of TensorType.
  // F64Tensor corresponds to a 64-bit floating-point TensorType.
  let results = (outs F64Tensor);
}</code></pre></div><h4 id=verifying-operation-semantics>Verifying Operation Semantics</h4><p>At this point we&rsquo;ve already covered a majority of the original C++ operation
definition. The next piece to define is the verifier. Luckily, much like the
named accessor, the ODS framework will automatically generate a lot of the
necessary verification logic based upon the constraints we have given. This
means that we don&rsquo;t need to verify the structure of the return type, or even the
input attribute <code>value</code>. In many cases, additional verification is not even
necessary for ODS operations. To add additional verification logic, an operation
can override the <a href=../../OpDefinitions.md#custom-verifier-code><code>verifier</code></a>
field. The <code>verifier</code> field allows for defining a C++ code blob that will be run
as part of <code>ConstantOp::verify</code>. This blob can assume that all of the other
invariants of the operation have already been verified:</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>def ConstantOp : Toy_Op&lt;&#34;constant&#34;, [NoSideEffect]&gt; {
  // Provide a summary and description for this operation. This can be used to
  // auto-generate documentation of the operations within our dialect.
  let summary = &#34;constant operation&#34;;
  let description = [{
    Constant operation turns a literal into an SSA value. The data is attached
    to the operation as an attribute. For example:

      %0 = &#34;toy.constant&#34;()
         { value = dense&lt;[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]&gt; : tensor&lt;2x3xf64&gt; }
        : () -&gt; tensor&lt;2x3xf64&gt;
  }];

  // The constant operation takes an attribute as the only input.
  // `F64ElementsAttr` corresponds to a 64-bit floating-point ElementsAttr.
  let arguments = (ins F64ElementsAttr:$value);

  // The generic call operation returns a single value of TensorType.
  // F64Tensor corresponds to a 64-bit floating-point TensorType.
  let results = (outs F64Tensor);

  // Add additional verification logic to the constant operation. Here we invoke
  // a static `verify` method in a C++ source file. This codeblock is executed
  // inside of ConstantOp::verify, so we can use `this` to refer to the current
  // operation instance.
  let verifier = [{ return ::verify(*this); }];
}</code></pre></div><h4 id=attaching-build-methods>Attaching <code>build</code> Methods</h4><p>The final missing component here from our original C++ example are the <code>build</code>
methods. ODS can generate some simple build methods automatically, and in this
case it will generate our first build method for us. For the rest, we define the
<a href=../../OpDefinitions.md#custom-builder-methods><code>builders</code></a> field. This field
takes a list of <code>OpBuilder</code> objects that take a string corresponding to a list
of C++ parameters, as well as an optional code block that can be used to specify
the implementation inline.</p><div class=highlight><pre class=chroma><code class=language-tablegen data-lang=tablegen>def ConstantOp : Toy_Op&lt;&#34;constant&#34;, [NoSideEffect]&gt; {
  // Provide a summary and description for this operation. This can be used to
  // auto-generate documentation of the operations within our dialect.
  let summary = &#34;constant operation&#34;;
  let description = [{
    Constant operation turns a literal into an SSA value. The data is attached
    to the operation as an attribute. For example:

      %0 = &#34;toy.constant&#34;()
         { value = dense&lt;[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]&gt; : tensor&lt;2x3xf64&gt; }
        : () -&gt; tensor&lt;2x3xf64&gt;
  }];

  // The constant operation takes an attribute as the only input.
  // `F64ElementsAttr` corresponds to a 64-bit floating-point ElementsAttr.
  let arguments = (ins F64ElementsAttr:$value);

  // The generic call operation returns a single value of TensorType.
  // F64Tensor corresponds to a 64-bit floating-point TensorType.
  let results = (outs F64Tensor);

  // Add additional verification logic to the constant operation. Here we invoke
  // a static `verify` method in a c++ source file. This codeblock is executed
  // inside of ConstantOp::verify, so we can use `this` to refer to the current
  // operation instance.
  let verifier = [{ return ::verify(*this); }];

  // Add custom build methods for the constant operation. These methods populate
  // the `state` that MLIR uses to create operations, i.e. these are used when
  // using `builder.create&lt;ConstantOp&gt;(...)`.
  let builders = [
    // Build a constant with a given constant tensor value.
    OpBuilder&lt;&#34;Builder *builder, OperationState &amp;result, &#34;
              &#34;DenseElementsAttr value&#34;, [{
      // Call into an autogenerated `build` method.
      build(builder, result, value.getType(), value);
    }]&gt;,

    // Build a constant with a given constant floating-point value. This builder
    // creates a declaration for `ConstantOp::build` with the given parameters.
    OpBuilder&lt;&#34;Builder *builder, OperationState &amp;result, double value&#34;&gt;
  ];
}</code></pre></div><p>Above we introduce several of the concepts for defining operations in the ODS
framework, but there are many more that we haven&rsquo;t had a chance to: regions,
variadic operands, etc. Check out the
<a href=../../OpDefinitions.md>full specification</a> for more details.</p><h2 id=complete-toy-example>Complete Toy Example</h2><p>At this point we can generate our &ldquo;Toy IR&rdquo;. A simplified version of the previous
example:</p><div class=highlight><pre class=chroma><code class=language-.toy data-lang=.toy>def multiply_transpose(a, b) {
  return transpose(a) * transpose(b);
}

def main() {
  var a&lt;2, 3&gt; = [[1, 2, 3], [4, 5, 6]];
  var b&lt;2, 3&gt; = [1, 2, 3, 4, 5, 6];
  var c = multiply_transpose(a, b);
  var d = multiply_transpose(b, a);
  print(d);
}</code></pre></div><p>Results in the following IR:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module {
  func @multiply_transpose(%arg0: tensor&lt;*xf64&gt;, %arg1: tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; {
    %0 = &#34;toy.transpose&#34;(%arg0) : (tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; loc(&#34;test/codegen.toy&#34;:5:10)
    %1 = &#34;toy.transpose&#34;(%arg1) : (tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; loc(&#34;test/codegen.toy&#34;:5:25)
    %2 = &#34;toy.mul&#34;(%0, %1) : (tensor&lt;*xf64&gt;, tensor&lt;*xf64&gt;) -&gt; tensor&lt;*xf64&gt; loc(&#34;test/codegen.toy&#34;:5:25)
    &#34;toy.return&#34;(%2) : (tensor&lt;*xf64&gt;) -&gt; () loc(&#34;test/codegen.toy&#34;:5:3)
  } loc(&#34;test/codegen.toy&#34;:4:1)
  func @main() {
    %0 = &#34;toy.constant&#34;() {value = dense&lt;[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]&gt; : tensor&lt;2x3xf64&gt;} : () -&gt; tensor&lt;2x3xf64&gt; loc(&#34;test/codegen.toy&#34;:9:17)
    %1 = &#34;toy.reshape&#34;(%0) : (tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;2x3xf64&gt; loc(&#34;test/codegen.toy&#34;:9:3)
    %2 = &#34;toy.constant&#34;() {value = dense&lt;[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]&gt; : tensor&lt;6xf64&gt;} : () -&gt; tensor&lt;6xf64&gt; loc(&#34;test/codegen.toy&#34;:10:17)
    %3 = &#34;toy.reshape&#34;(%2) : (tensor&lt;6xf64&gt;) -&gt; tensor&lt;2x3xf64&gt; loc(&#34;test/codegen.toy&#34;:10:3)
    %4 = &#34;toy.generic_call&#34;(%1, %3) {callee = @multiply_transpose} : (tensor&lt;2x3xf64&gt;, tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;*xf64&gt; loc(&#34;test/codegen.toy&#34;:11:11)
    %5 = &#34;toy.generic_call&#34;(%3, %1) {callee = @multiply_transpose} : (tensor&lt;2x3xf64&gt;, tensor&lt;2x3xf64&gt;) -&gt; tensor&lt;*xf64&gt; loc(&#34;test/codegen.toy&#34;:12:11)
    &#34;toy.print&#34;(%5) : (tensor&lt;*xf64&gt;) -&gt; () loc(&#34;test/codegen.toy&#34;:13:3)
    &#34;toy.return&#34;() : () -&gt; () loc(&#34;test/codegen.toy&#34;:8:1)
  } loc(&#34;test/codegen.toy&#34;:8:1)
} loc(&#34;test/codegen.toy&#34;:0:0)</code></pre></div><p>You can build <code>toyc-ch2</code> and try yourself: <code>toyc-ch2
test/Examples/Toy/Ch2/codegen.toy -emit=mlir -mlir-print-debuginfo</code>. We can also
check our RoundTrip: <code>toyc-ch2 test/Examples/Toy/Ch2/codegen.toy -emit=mlir
-mlir-print-debuginfo 2&gt; codegen.mlir</code> followed by <code>toyc-ch2 codegen.mlir
-emit=mlir</code>. You should also use <code>mlir-tblgen</code> on the final definition file and
study the generated C++ code.</p><p>At this point, MLIR knows about our Toy dialect and operations. In the
<a href=Ch-3.md>next chapter</a>, we will leverage our new dialect to implement some
high-level language-specific analyses and transformations for the Toy language.</p><div class=edit-meta>Last updated on 1 Jan 1970<br>Published on 1 Jan 1970<br><a href=https://github.com/llvm/mlir-www//edit/master/website/content/docs/Tutorials/Toy/Ch-2.md class=edit-page><i class="fas fa-pen-square"></i>Edit on GitHub</a></div><nav class=pagination><a class="nav nav-prev" href=/docs/Tutorials/Toy/Ch-1/ title="Chapter 1: Toy Tutorial Introduction"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Chapter 1: Toy Tutorial Introduction</a>
<a class="nav nav-next" href=/docs/Tutorials/Toy/Ch-3/ title="Chapter 3: High-level Language-Specific Analysis and Transformation">Next - Chapter 3: High-level Language-Specific Analysis and Transformation <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Affine/>Affine Dialect</a></li><li><a href=/docs/Dialects/AffineOps/>Dialect &#39;affine&#39; definition</a></li><li><a href=/docs/Dialects/FxpMathOps/>Dialect &#39;fxpmath&#39; definition</a></li><li><a href=/docs/Dialects/GPUOps/>Dialect &#39;gpu&#39; definition</a></li><li><a href=/docs/Dialects/LinalgDoc/>Dialect &#39;linalg&#39; definition</a></li><li><a href=/docs/Dialects/LoopOps/>Dialect &#39;loop&#39; definition</a></li><li><a href=/docs/Dialects/NVVMOps/>Dialect &#39;nvvm&#39; definition</a></li><li><a href=/docs/Dialects/QuantOps/>Dialect &#39;quant&#39; definition</a></li><li><a href=/docs/Dialects/ROCDLOps/>Dialect &#39;rocdl&#39; definition</a></li><li><a href=/docs/Dialects/SPIRVOps/>Dialect &#39;spv&#39; definition</a></li><li><a href=/docs/Dialects/VectorOps/>Dialect &#39;vector&#39; definition</a></li><li><a href=/docs/Dialects/GPU/>GPU Dialect</a></li><li><a href=/docs/Dialects/Linalg/>Linalg Dialect</a></li><li><a href=/docs/Dialects/LLVM/>LLVM IR Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>SPIR-V Dialect</a></li><li><a href=/docs/Dialects/Standard/>Standard Dialect</a></li><li><a href=/docs/Dialects/Vector/>Vector Dialect</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/Tutorials/Toy/>Toy<span class="mark opened">-</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Tutorial Introduction</a></li><li class=active><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/Diagnostics/>Introduction and Usage Guide to MLIR&#39;s Diagnostics Infrastructure</a></li><li><a href=/docs/Interfaces/>Introduction to MLIR Interfaces</a></li><li><a href=/docs/Traits/>Introduction to MLIR Operation Traits</a></li><li><a href=/docs/GenericDAGRewriter/>MLIR Generic DAG Rewriter Infrastructure</a></li><li><a href=/docs/Passes/>MLIR Passes</a></li><li><a href=/docs/Quantization/>MLIR Quantization</a></li><li><a href=/docs/Rationale/>MLIR Rationale</a></li><li><a href=/docs/LangRef/>MLIR Specification</a></li><li><a href=/docs/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a &lt;em&gt;simplified&lt;/em&gt; polyhedral form</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization in MLIR</a></li><li><a href=/docs/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li><a href=/docs/DefiningAttributesAndTypes/>Quickstart tutorial to defining custom dialect attributes and types</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/OpDefinitions/>Table-driven Operation Definition Specification (ODS)</a></li><li><a href=/docs/UsageOfConst/>Usage of &#39;Const&#39; in MLIR, for core IR types</a></li><li><a href=/docs/WritingAPass/>Writing a Pass</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>