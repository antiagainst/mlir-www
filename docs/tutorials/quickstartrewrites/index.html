<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Quickstart on Graph Rewrite - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.59.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/tutorials/quickstartrewrites/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/llvm-project/mlir>Forums</a></li><li class=child><a href=https://discord.gg/JUQUPAZ>Chat</a></li></ul></li><li><a href=/getting_started/faq/>FAQ</a></li><li><a href=https://github.com/llvm/llvm-project/mlir>Source</a></li></ul></nav></div><div class=content-container><main><h1>Quickstart on Graph Rewrite</h1><p>This document will present a quickstart to adding graph rewrites. We shall start
by defining an operation, showing multiple ways to define the rewrite using
patterns, as well as defining the rewrite using a graph walker (note: using
patterns and the rewrite engine is preferred, showing the walker is for
demonstration purposes).</p><p>See <a href=LangRef.md>MLIR specification</a> for more information about MLIR, the
structure of the IR, operations, etc. See
<a href=OpDefinitions.md>Table-driven Operation Definition</a> and
<a href=DeclarativeRewrites.md>Declarative Rewrite Rule</a> for the detailed explanation
of all available mechanisms for defining operations and rewrites in a
table-driven manner.</p><h2 id=adding-operation>Adding operation</h2><p>An operation in MLIR is specified using a definition in
<a href=https://llvm.org/docs/TableGen/LangIntro.html>TableGen</a> file. TableGen is a
modeling tool to specify the ops and the C++ code to interact with these
operations are generated from. To define an operation one needs to specify:</p><ul><li>The operation name. This name is a unique identifier of the operation within
MLIR. Most operations are within a dialect, so for example one could have
<code>tfl.add</code> to represent the add operation in the TensorFlow Lite dialect.
Instead of repeating the dialect in the op definition, a base class for the
op dialect is commonly created that prepends the dialect namespace given an
op name.</li><li>The traits of the operation. These allow you to specify traits of the
operation, such as whether it has side effects or whether it should be
verified that the operands and result types are the same. These are backed
by C++ traits that perform the verification.</li><li>The arguments of the operation. These are the input operands (values at
runtime produced by other ops) and attributes (compile time known constant
values that affect the behavior of the op) that are the inputs of/define the
behavior of the operation. The input operands may be named, the attributes
must be named.</li><li>The result(s) of the operation. These may again named or not.</li><li>Documentation of the operation. This includes a one-line summary as well as
a longer human-readable description of the operation.</li><li><p>Dialect specific information. Additional information could be added to the
operation definition that are only used by dialect specific drivers. These
are ignored by the main op and doc generators, but could be used in, say,
the translation from a dialect to another representation.</p><div class=highlight><pre class=chroma><code class="language-td {.td}" data-lang="td {.td}">def TFL_LeakyReluOp: TFL_Op&lt;TFL_Dialect, &#34;leaky_relu&#34;,
                        [NoSideEffect, SameValueType]&gt;,
                 Results&lt;(outs Tensor)&gt; {
let arguments = (ins
F32Tensor:$x,
// Slope of the activation function at x &lt; 0.
F32Attr:$alpha
);

let summary = &#34;Leaky ReLU operator&#34;;
let description = [{
Element-wise Leaky ReLU operator
  x -&gt; x &gt;= 0 ? x : (alpha * x)
}];

// TFLite specific attribute that is used when generating the output
// flatbuffer.
let hasOptions = 1;
}</code></pre></div></li></ul><p>Note in the above the result types and inputs are specified in different ways,
one by way of trait and the other by way of let. It is possible to specify both
in either way.</p><p>Operations can also have custom parser, printer, builder, verifier, constant
folder, or canonicalizer. These require specifying additional C++ methods to
invoke for additional functionality. For example, if an operation is marked to
have a folder, the constant folder also needs to be added, e.g.,:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=n>OpFoldResult</span> <span class=n>SpecificOp</span><span class=o>::</span><span class=n>fold</span><span class=p>(</span><span class=n>ArrayRef</span><span class=o>&lt;</span><span class=n>Attribute</span><span class=o>&gt;</span> <span class=n>constOperands</span><span class=p>)</span> <span class=p>{</span>
  <span class=k>if</span> <span class=p>(</span><span class=n>unable_to_fold</span><span class=p>)</span>
    <span class=k>return</span> <span class=p>{};</span>
  <span class=p>....</span>
  <span class=k>return</span> <span class=n>val</span><span class=p>;</span>
<span class=p>}</span>
</code></pre></div><h2 id=adding-patterns>Adding patterns</h2><p>There are multiple forms of graph rewrite that can be performed in MLIR. One of
the most common is DAG tile to DAG tile rewrite. Patterns provide a concise way
to express this transformation as a pair of source pattern to match and
resultant pattern. There are both the C++ classes to represent this
transformation, as well as the patterns in TableGen from which these can be
generated.</p><h3 id=tablegen-patterns>TableGen patterns</h3><p>Let us continue with LeakyRelu. To map from TensorFlow&rsquo;s <code>LeakyRelu</code> to
TensorFlow Lite&rsquo;s <code>LeakyRelu</code>:</p><div class=highlight><pre class=chroma><code class="language-td {.td}" data-lang="td {.td}">def : Pat&lt;(TF_LeakyReluOp $arg, F32Attr:$a), (TFL_LeakyReluOp $arg, $a)&gt;</code></pre></div><p>The pattern is specified by instantiating a <code>Pat</code> with a source and result DAG.
The arguments in the source pattern is captured and can be used in the result
pattern. This is a simple pattern as we have a 1:1 mapping and the attribute
does not need to be transformed (e.g., both have a floating point attribute for
alpha). The names of the attributes specified in the pattern is for
matching/referencing and need not match the original attribute name in the op
definition but the order of arguments of the dags do need to match.</p><p>To specify a pattern, both the source and resultant ops need to be defined using
TableGen.</p><p>If this were a more advance pattern that the current framework could not express
as destination then one could use a general native code fallback method. This
consists of defining a pattern as well as adding a C++ function to perform the
replacement:</p><div class=highlight><pre class=chroma><code class="language-td {.td}" data-lang="td {.td}">def createTFLLeakyRelu : NativeCodeCall&lt;
    &#34;createTFLLeakyRelu($_builder, $0-&gt;getDefiningOp(), $1, $2)&#34;&gt;;

def : Pat&lt;(TF_LeakyReluOp:$old_value, $arg, F32Attr:$a),
          (createTFLLeakyRelu $old_value, $arg, $a)&gt;;</code></pre></div><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=k>static</span> <span class=n>Value</span><span class=o>*</span> <span class=nf>createTFLLeakyRelu</span><span class=p>(</span><span class=n>PatternRewriter</span> <span class=o>&amp;</span><span class=n>rewriter</span><span class=p>,</span> <span class=n>Operation</span> <span class=o>*</span><span class=n>op</span><span class=p>,</span>
                                 <span class=n>Value</span><span class=o>*</span> <span class=n>operand</span><span class=p>,</span> <span class=n>Attribute</span> <span class=n>attr</span><span class=p>)</span> <span class=p>{</span>
  <span class=k>return</span> <span class=n>rewriter</span><span class=p>.</span><span class=n>create</span><span class=o>&lt;</span><span class=n>mlir</span><span class=o>::</span><span class=n>TFL</span><span class=o>::</span><span class=n>LeakyReluOp</span><span class=o>&gt;</span><span class=p>(</span>
      <span class=n>op</span><span class=o>-&gt;</span><span class=n>getLoc</span><span class=p>(),</span> <span class=n>operands</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>-&gt;</span><span class=n>getType</span><span class=p>(),</span> <span class=cm>/*arg=*/</span><span class=n>operands</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span>
      <span class=cm>/*alpha=*/</span><span class=n>attrs</span><span class=p>[</span><span class=mi>0</span><span class=p>].</span><span class=n>cast</span><span class=o>&lt;</span><span class=n>FloatAttr</span><span class=o>&gt;</span><span class=p>());</span>
<span class=p>}</span>
</code></pre></div><p>This allows for arbitrarily complex builders. Input pattern side one can express
multi-op patterns with constraints on input operands and attributes. But input
patterns cannot yet express constraints across multiple operands/attributes.</p><h3 id=register-the-pattern>Register the pattern</h3><p>The file containing the patterns need to be processed using <code>mlir-tblgen</code>
<code>-gen-rewriters</code> during compilation time. It can be invoked with the following
configuration in CMake:</p><div class=highlight><pre class=chroma><code class=language-cmake data-lang=cmake><span class=nb>set</span><span class=p>(</span><span class=s>LLVM_TARGET_DEFINITIONS</span> <span class=s>&lt;name-of-the-td-file&gt;</span><span class=p>)</span><span class=err>
</span><span class=err></span><span class=nb>mlir_tablegen</span><span class=p>(</span><span class=s>&lt;name-of-the-generated-inc-file&gt;</span> <span class=s>-gen-rewriters</span><span class=p>)</span><span class=err>
</span><span class=err></span><span class=nb>add_public_tablegen_target</span><span class=p>(</span><span class=s>&lt;name-of-the-cmake-target&gt;</span><span class=p>)</span></code></pre></div><p>Then you can <code>#include</code> the generated file in any C++ implementation file you
like. (You will also need to make sure the library depends on the CMake target
defined in the above.) The generated file will have a <code>populateWithGenerated(
MLIRContext *context, OwningRewritePatternList *patterns)</code> function that you can
use to collect all the generated patterns inside <code>patterns</code> and then use
<code>patterns</code> in any pass you would like.</p><h3 id=c-rewrite-specification>C++ rewrite specification</h3><p>In case patterns are not sufficient there is also the fully C++ way of
expressing a rewrite:</p><div class=highlight><pre class=chroma><code class=language-c++ data-lang=c++><span class=c1>/// Multi-step rewrite using &#34;match&#34; and &#34;rewrite&#34;. This allows for separating
</span><span class=c1>/// the concerns of matching and rewriting.
</span><span class=c1></span><span class=k>struct</span> <span class=nc>ConvertTFLeakyRelu</span> <span class=o>:</span> <span class=k>public</span> <span class=n>RewritePattern</span> <span class=p>{</span>
  <span class=n>ConvertTFLeakyRelu</span><span class=p>(</span><span class=n>MLIRContext</span> <span class=o>*</span><span class=n>context</span><span class=p>)</span>
      <span class=o>:</span> <span class=n>RewritePattern</span><span class=p>(</span><span class=s>&#34;tf.LeakyRelu&#34;</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>context</span><span class=p>)</span> <span class=p>{}</span>

  <span class=n>PatternMatchResult</span> <span class=nf>match</span><span class=p>(</span><span class=n>Operation</span> <span class=o>*</span><span class=n>op</span><span class=p>)</span> <span class=k>const</span> <span class=k>override</span> <span class=p>{</span>
    <span class=k>return</span> <span class=n>matchSuccess</span><span class=p>();</span>
  <span class=p>}</span>

  <span class=kt>void</span> <span class=nf>rewrite</span><span class=p>(</span><span class=n>Operation</span> <span class=o>*</span><span class=n>op</span><span class=p>,</span> <span class=n>PatternRewriter</span> <span class=o>&amp;</span><span class=n>rewriter</span><span class=p>)</span> <span class=k>const</span> <span class=k>override</span> <span class=p>{</span>
    <span class=n>rewriter</span><span class=p>.</span><span class=n>replaceOpWithNewOp</span><span class=o>&lt;</span><span class=n>TFL</span><span class=o>::</span><span class=n>LeakyReluOp</span><span class=o>&gt;</span><span class=p>(</span>
        <span class=n>op</span><span class=p>,</span> <span class=n>op</span><span class=o>-&gt;</span><span class=n>getResult</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>-&gt;</span><span class=n>getType</span><span class=p>(),</span> <span class=n>op</span><span class=o>-&gt;</span><span class=n>getOperand</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span>
        <span class=cm>/*alpha=*/</span><span class=n>op</span><span class=o>-&gt;</span><span class=n>getAttrOfType</span><span class=o>&lt;</span><span class=n>FloatAttr</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&#34;alpha&#34;</span><span class=p>));</span>
  <span class=p>}</span>
<span class=p>};</span>

<span class=c1>/// Single-step rewrite with &#34;matchAndRewrite&#34;. This allows for performing the
</span><span class=c1>/// rewrite immediately upon a successful match.
</span><span class=c1></span><span class=k>struct</span> <span class=nc>ConvertTFLeakyRelu</span> <span class=o>:</span> <span class=k>public</span> <span class=n>RewritePattern</span> <span class=p>{</span>
  <span class=n>ConvertTFLeakyRelu</span><span class=p>(</span><span class=n>MLIRContext</span> <span class=o>*</span><span class=n>context</span><span class=p>)</span>
      <span class=o>:</span> <span class=n>RewritePattern</span><span class=p>(</span><span class=s>&#34;tf.LeakyRelu&#34;</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>context</span><span class=p>)</span> <span class=p>{}</span>

  <span class=n>PatternMatchResult</span> <span class=nf>matchAndRewrite</span><span class=p>(</span><span class=n>Operation</span> <span class=o>*</span><span class=n>op</span><span class=p>,</span>
                                     <span class=n>PatternRewriter</span> <span class=o>&amp;</span><span class=n>rewriter</span><span class=p>)</span> <span class=k>const</span> <span class=k>override</span> <span class=p>{</span>
    <span class=n>rewriter</span><span class=p>.</span><span class=n>replaceOpWithNewOp</span><span class=o>&lt;</span><span class=n>TFL</span><span class=o>::</span><span class=n>LeakyReluOp</span><span class=o>&gt;</span><span class=p>(</span>
        <span class=n>op</span><span class=p>,</span> <span class=n>op</span><span class=o>-&gt;</span><span class=n>getResult</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>-&gt;</span><span class=n>getType</span><span class=p>(),</span> <span class=n>op</span><span class=o>-&gt;</span><span class=n>getOperand</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span>
        <span class=cm>/*alpha=*/</span><span class=n>op</span><span class=o>-&gt;</span><span class=n>getAttrOfType</span><span class=o>&lt;</span><span class=n>FloatAttr</span><span class=o>&gt;</span><span class=p>(</span><span class=s>&#34;alpha&#34;</span><span class=p>));</span>
    <span class=k>return</span> <span class=n>matchSuccess</span><span class=p>();</span>
  <span class=p>}</span>
<span class=p>};</span>
</code></pre></div><p>In the C++ rewrite the static benefit of the rewrite pattern is specified at
construction. While in the pattern generator a simple heuristic is currently
employed based around the number of ops matched and replaced.</p><p>The above rule did not capture the matching operands/attributes, but in general
the <code>match</code> function in a multi-step rewrite may populate and return a
<code>PatternState</code> (or class derived from one) to pass information extracted during
matching to the rewrite. A single-step rewrite with the <code>matchAndRewrite</code>
function has the benefit of being able to directly use any values created when
matching; removing the need for <code>PatternState</code>.</p><h2 id=testing>Testing</h2><p>MLIR uses <a href=https://llvm.org/docs/CommandGuide/lit.html>lit</a> (LLVM Integrated
Testing) tool for performing testing. Testing is performed by way of creating
the input IR file, running a transformation and then verifying the output IR.
C++ unit tests are the exception, with the IR transformation serving as the core
testing mechanism. This results in fewer binaries that need to be built (and
linked) and forces to focus on the representation as an important piece.</p><p>For the legalization transform above we would have a test (probably as part of
the legalization pass test in TensorFlow Lite) such as:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>// RUN: mlir-opt -tfl-legalize-tf %s | FileCheck %s

func @LeakyRelu(%arg0: tensor&lt;1xf32&gt;) -&gt; tensor&lt;1xf32&gt; {
  %2 = &#34;tf.LeakyRelu&#34;(%arg0) {alpha: 0.1} : (tensor&lt;1xf32&gt;) -&gt; tensor&lt;1xf32&gt;
  return %2: tensor&lt;1xf32&gt;

// CHECK-LABEL: LeakyRelu
// CHECK:  %0 = &#34;tfl.leaky_relu&#34;(%arg0) {alpha: 1.000000e-01} : (tensor&lt;1xf32&gt;) -&gt; tensor&lt;1xf32&gt;
}</code></pre></div><p>The RUN command at the top results in running the <code>mlir-opt</code> binary (which is
compiler writer tool to exercise different registered passes) to invoke the
optimization pass this transform was added as part of on the current file and to
verify its output using <code>FileCheck</code>. <code>FileCheck</code> is textual output verifier. In
particular it uses the CHECK expressions to verify the given output is produced.</p><p>There can be multiple RUN commands with different corresponding CHECK prefixes.
And in addition multiple independent tests separated by <code>// -----</code> and
<code>mlir-opt</code> invoked with <code>-split-input-file</code> flag. This is especially useful for
error testing.</p><p>This results in very simple, directed testing without need to work around
constant propagation or other, unrelated, optimization passes.</p><h2 id=adding-optimization-pass>Adding optimization pass</h2><p>Optimization passes that do not fit/are difficult to specify in the above
structure can be specified as general iterations across modules/functions. See
<a href=WritingAPass.md>Writing a Pass</a> for a general overview and introduction to
optimization passes in MLIR.</p><div class=edit-meta>Last updated on 29 Nov 2019<br>Published on 29 Nov 2019<br><a href=https://github.com/llvm/mlir-www//edit/master/content/docs/Tutorials/QuickstartRewrites.md class=edit-page><i class="fas fa-pen-square"></i>Edit on GitHub</a></div><nav class=pagination><a class="nav nav-prev" href=/docs/tutorials/toy/ch-7/ title="Chapter 7: Adding a Composite Type to Toy"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Chapter 7: Adding a Composite Type to Toy</a>
<a class="nav nav-next" href=/docs/tutorials/toy/ title="Toy Tutorial">Next - Toy Tutorial <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=open-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/getting_started/>Getting Started</a><ul class=sub-menu><li><a href=/getting_started/faq/>FAQ</a></li><li><a href=/getting_started/developerguide/>Developer Guide</a></li><li><a href=/getting_started/glossary/>Glossary</a></li><li><a href=/getting_started/testingguide/>Testing Guide</a></li></ul></li><li class=parent><a href=/docs/>Docs</a><ul class=sub-menu><li class=parent><a href=/docs/tutorials/>Tutorials</a><ul class=sub-menu><li><a href=/docs/tutorials/dialectconversion/>Dialect Conversion</a></li><li><a href=/docs/tutorials/interfaces/>Interfaces</a></li><li><a href=/docs/tutorials/traits/>Introduction to Operation Traits</a></li><li class=active><a href=/docs/tutorials/quickstartrewrites/>Quickstart on Graph Rewrite</a></li><li><a href=/docs/tutorials/toy/>Toy Tutorial</a><ul class=sub-menu><li><a href=/docs/tutorials/toy/ch-1/>Chapter 1: Intro</a></li><li><a href=/docs/tutorials/toy/ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/tutorials/toy/ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/tutorials/toy/ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/tutorials/toy/ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/tutorials/toy/ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/tutorials/toy/ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li></ul></li><li><a href=/docs/dialects/>Dialect</a><ul class=sub-menu><li><a href=/docs/dialects/affine/>Affine</a></li><li><a href=/docs/dialects/gpu/>GPU Dialect</a></li><li><a href=/docs/dialects/llvm/>LLVM IR Dialect</a></li><li><a href=/docs/dialects/spir-v/>SPIR-V Dialect</a></li><li><a href=/docs/dialects/standard/>Standard Dialect</a></li><li><a href=/docs/dialects/vector/>Vector Dialect</a></li><li><a href=/docs/dialects/affineops/>Dialect &#39;affine&#39; definition</a></li><li><a href=/docs/dialects/fxpmathops/>Dialect &#39;fxpmath&#39; definition</a></li><li><a href=/docs/dialects/gpuops/>Dialect &#39;gpu&#39; definition</a></li><li><a href=/docs/dialects/linalgops/>Dialect &#39;linalg&#39; definition</a></li><li><a href=/docs/dialects/loopops/>Dialect &#39;loop&#39; definition</a></li><li><a href=/docs/dialects/nvvmops/>Dialect &#39;nvvm&#39; definition</a></li><li><a href=/docs/dialects/quantops/>Dialect &#39;quant&#39; definition</a></li><li><a href=/docs/dialects/rocdlops/>Dialect &#39;rocdl&#39; definition</a></li><li><a href=/docs/dialects/spirvops/>Dialect &#39;spv&#39; definition</a></li><li><a href=/docs/dialects/vectorops/>Dialect &#39;vector&#39; definition</a></li></ul></li><li><a href=/docs/design/>Design</a><ul class=sub-menu><li><a href=/docs/design/canonicalization/>Canonicalization</a></li><li><a href=/docs/design/rationalesimplifiedpolyhedralform/>Case for a Simplified Polyhedral Form</a></li><li><a href=/docs/design/rationale/>Design Rationale</a></li><li><a href=/docs/design/diagnostics/>Diagnostics Infrastructure</a></li><li><a href=/docs/design/edsc/>EDSC: Declarative Builders</a></li><li><a href=/docs/design/genericdagrewriter/>Generic DAG Rewriter Infrastructure</a></li><li><a href=/docs/design/mlirforgraphalgorithms/>Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/design/quantization/>Quantization</a></li><li><a href=/docs/design/declarativerewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/design/opdefinitions/>Table-driven Operation Definition Specification (ODS)</a></li><li><a href=/docs/design/usageofconst/>Usage of &#39;Const&#39; in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/conversiontollvmdialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/langref/>Core Specification</a></li><li><a href=/docs/passes/>Passes</a></li><li><a href=/docs/definingattributesandtypes/>Quickstart tutorial to defining custom dialect attributes and types</a></li><li><a href=/docs/writingapass/>Writing a Pass</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>